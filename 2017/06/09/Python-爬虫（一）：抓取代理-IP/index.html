<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="linux | python | 爬虫 | 华为网络工程师 | HCNA | HCNP"><title>Python 爬虫（一）：抓取代理 IP | Song F</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python 爬虫（一）：抓取代理 IP</h1><a id="logo" href="/.">Song F</a><p class="description">Liu's blog</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python 爬虫（一）：抓取代理 IP</h1><div class="post-meta">Jun 9, 2017<span> | </span><span class="category"><a href="/categories/Python/">Python</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><h5 id="准备："><a href="#准备：" class="headerlink" title="准备："></a>准备：</h5><ul>
<li>Python 3 的基础知识</li>
<li>Beautifulsoup 、Requests 、Selenium 库的基本使用</li>
</ul>
<h5 id="工具："><a href="#工具：" class="headerlink" title="工具："></a>工具：</h5><ul>
<li>Python 3 及以上版本</li>
<li>Pycharm 2017 软件</li>
<li>Chrome 浏览器</li>
<li><a href="https://www.songf.win/2017/06/17/centos-7-%E5%AE%89%E8%A3%85phantomjs/">PhantomJS</a> 软件</li>
<li>Requests 、Beautifulsoup 、Selenium 、time 库</li>
</ul>
<h5 id="爬取的网站："><a href="#爬取的网站：" class="headerlink" title="爬取的网站："></a>爬取的网站：</h5><ul>
<li><a href="http://www.cybersyndrome.net/pla6.html" target="_blank" rel="external">cybersyndrome</a></li>
<li><a href="http://www.xicidaili.com/nn" target="_blank" rel="external">西刺代理</a></li>
</ul>
<h5 id="踩过的坑："><a href="#踩过的坑：" class="headerlink" title="踩过的坑："></a>踩过的坑：</h5><ul>
<li>写爬虫前最好看一下网页的源码。否则，辛辛苦苦写完代码，却发现，网页内容是用 JS 呈现的，用 Beautifulsoup 根本抓不到</li>
</ul>
<h5 id="过程："><a href="#过程：" class="headerlink" title="过程："></a>过程：</h5><p>首先，导入必须的库和请求需要的 Headers 头<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#-*-coding:utf-8-*-</span></div><div class="line"></div><div class="line"><span class="comment"># 导入需要的库</span></div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</div><div class="line"></div><div class="line"><span class="comment"># 发送 http 请求需要的 headers 头</span></div><div class="line">headers = &#123;</div><div class="line">  <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 UBrowser/6.1.2716.203 Safari/537.36'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># 最终所有的结果存储在这个列表中</span></div><div class="line">result = []</div></pre></td></tr></table></figure></p>
<ul>
<li><h6 id="爬取-cybersyndrome"><a href="#爬取-cybersyndrome" class="headerlink" title="爬取 cybersyndrome"></a>爬取 cybersyndrome</h6></li>
</ul>
<p>通过查看网页源码，你会发现，整个网页上的 IP 全是用以下 JS 代码来呈现的，用 Beautifulsoup 是抓不到的。</p>
<p><img src="http://or6ijpi19.bkt.clouddn.com/%E7%BD%91%E9%A1%B5%E6%BA%90%E7%A0%81-js.png?imageView2/2/w/750/h/750/q/75|imageslim" alt="网页源码"></p>
<p>不得以，要使用 Selenium 与 PhantomJS 来配合抓取网页了。</p>
<p>首先，分析网页。右键“检查”网页，会发现，IP 全都在一个无序列表中 <strong>a</strong>  标签内。这就方便很多了。<br>Selenium 查找元素的方法有很多种，但是，分析一下 IP 所在的 <strong>a</strong>  标签，每个标签的id、title 都不尽相同，只有 class 是相对比较固定的。虽然网页语言是日语，但是如果你大体上看一下网页上方的介绍，会发现所有的 IP 被分为三类：赤色（A）、青色（B）、绿色（C）。正好对应于 <strong>a</strong> 标签的三种 class，<em>class = A</em>、<em>class = B</em>、<em>class = C</em>。<br><img src="http://or6ijpi19.bkt.clouddn.com/class-A.png" alt="class = A"></p>
<p><img src="http://or6ijpi19.bkt.clouddn.com/class-B.png" alt="class = B"></p>
<p><img src="http://or6ijpi19.bkt.clouddn.com/class-C.png" alt="class = C"></p>
<p>然后，开写代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 获取网页</span></div><div class="line">browser = webdriver.PhantomJS(executable_path=<span class="string">'D:\PhantomJS'</span>)   </div><div class="line"><span class="comment"># 因为我使用的 PhantomJS 软件未加入到系统 PATH 之中，只能这样调用</span></div><div class="line">browser.get(<span class="string">'http://www.cybersyndrome.net/pla6.html'</span>)</div><div class="line">time.sleep(<span class="number">5</span>)  <span class="comment"># 等待几秒，让网页加载完全</span></div><div class="line"></div><div class="line"><span class="comment"># 开始抓取</span></div><div class="line">ip_a = browser.find_elements_by_class_name(<span class="string">'A'</span>)    <span class="comment"># 此方法会返回一个列表</span></div><div class="line">ip_b = browser.find_elements_by_class_name(<span class="string">'B'</span>)</div><div class="line">ip_c = browser.find_elements_by_class_name(<span class="string">'C'</span>)</div><div class="line">browser.quit()</div><div class="line"><span class="comment"># 将获取到三个列表合为一个，注意，在此不能用列表相加，会出问题。诸位可以试一下</span></div><div class="line">address = []</div><div class="line"><span class="keyword">for</span> ip <span class="keyword">in</span> ip_a:</div><div class="line">    http = <span class="string">'http://'</span> + ip.text   <span class="comment"># 将得到的 IP 加上前缀</span></div><div class="line">    address.append(address)</div><div class="line"><span class="keyword">for</span> ip <span class="keyword">in</span> ip_b:</div><div class="line">    http = <span class="string">'http://'</span> + ip.text</div><div class="line">    address.append(address)</div><div class="line"><span class="keyword">for</span> ip <span class="keyword">in</span> ip_c:</div><div class="line">    http = <span class="string">'http://'</span> + ip.text</div><div class="line">    address.append(address)</div><div class="line">print(len(address))</div><div class="line">print(address)</div></pre></td></tr></table></figure></p>
<p>运行一下，看看情况</p>
<p><img src="http://or6ijpi19.bkt.clouddn.com/%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="运行结果"></p>
<p>总共抓取到 150 个结果，其中包括 三个误抓进来的，没事，不影响大局，稍后会写一个验证函数，剔除不能用的 IP。<br>因为要对每个 IP 进行验证，这部分代码要用很多遍，索性将这一部分独立出来写成一个函数，反复调用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 所谓的验证，也就是将 IP 用作代理地址去访问一个网址，看是否可以成功访问</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vf</span><span class="params">(pool,ip)</span>:</span>  <span class="comment"># pool是个列表</span></div><div class="line">	<span class="keyword">try</span>:</div><div class="line">    	response = requests.get(<span class="string">'http://www.baidu.com'</span>, headers=headers, proxies=&#123;<span class="string">'http'</span>:ip&#125;, timeout=<span class="number">3</span>)    <span class="comment"># 设置访问超时为 3s</span></div><div class="line">	<span class="keyword">except</span>:</div><div class="line">    	<span class="keyword">pass</span></div><div class="line">	<span class="keyword">else</span>:</div><div class="line">    	pool.append(ip)</div></pre></td></tr></table></figure>
<p>最后完善一下，写成一个函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cyb</span><span class="params">(ip_list)</span>:</span>    <span class="comment"># 调用的时候传入 result 列表</span></div><div class="line">    browser = webdriver.PhantomJS(executable_path=<span class="string">'D:\PhantomJS'</span>)</div><div class="line">    browser.get(<span class="string">'http://www.cybersyndrome.net/pla6.html'</span>)</div><div class="line">    time.sleep(<span class="number">5</span>)</div><div class="line">    ip_a = browser.find_elements_by_class_name(<span class="string">'A'</span>)</div><div class="line">    ip_b = browser.find_elements_by_class_name(<span class="string">'B'</span>)</div><div class="line">    ip_c = browser.find_elements_by_class_name(<span class="string">'C'</span>)</div><div class="line">    browser.quit()</div><div class="line">    address = []</div><div class="line">    <span class="keyword">for</span> ip <span class="keyword">in</span> ip_a:</div><div class="line">        http = <span class="string">'http://'</span> + ip.text</div><div class="line">        address.append(address)</div><div class="line">    <span class="keyword">for</span> ip <span class="keyword">in</span> ip_b:</div><div class="line">    	http = <span class="string">'http://'</span> + ip.text</div><div class="line">    	address.append(address)</div><div class="line">    <span class="keyword">for</span> ip <span class="keyword">in</span> ip_c:</div><div class="line">    	http = <span class="string">'http://'</span> + ip.text</div><div class="line">    	address.append(address)</div><div class="line">	<span class="keyword">for</span> ip <span class="keyword">in</span> address:</div><div class="line">    	vf(ip_list,ip)</div></pre></td></tr></table></figure>
<ul>
<li><h6 id="爬取西刺代理"><a href="#爬取西刺代理" class="headerlink" title="爬取西刺代理"></a>爬取西刺代理</h6></li>
</ul>
<p>首先分析网页。右键”检查“网页，会发现，所有的 IP 都在 <tr> 标签内。IP 在 </tr><tr> 内的第二个 <td> 标签内，端口号在第三个 </td><td> 标签内。</td></tr></p>
<p><img src="http://or6ijpi19.bkt.clouddn.com/IP_tr.png" alt=""></p>
<p>着手写代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">url = <span class="string">'http://www.xicidaili.com/nn1'</span></div><div class="line">page_data = requests.get(url,headers=headers)</div><div class="line">soup = BeautifulSoup(page_data.text,<span class="string">'lxml'</span>)</div><div class="line">items = soup.find_all(<span class="string">'tr'</span>)</div><div class="line">items.pop(<span class="number">0</span>)   <span class="comment"># 列表中第一个数据不是我们想要的，删掉。诸位可以将结果打印出来看一下第一个结果是什么</span></div><div class="line">address = []   <span class="comment"># 在最后将这一部分写为一个函数时，删掉 address 列表</span></div><div class="line"><span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">    ip = item.select(<span class="string">'td:nth-of-type(2)'</span>)[<span class="number">0</span>].get_text()</div><div class="line">    port = item.select(<span class="string">'td:nth-of-type(3)'</span>)[<span class="number">0</span>].get_text()</div><div class="line">    http = <span class="string">'http://'</span> + ip + <span class="string">':'</span> + port</div><div class="line">    vf(address,http)    <span class="comment"># 使用验证函数来验证 IP 是否可用</span></div><div class="line">print(address)</div></pre></td></tr></table></figure></p>
<p>运行，查看结果</p>
<p><img src="http://or6ijpi19.bkt.clouddn.com/QQ%E6%88%AA%E5%9B%BE20170609233517.png" alt=""></p>
<p>然后，分析网址构造，爬取多个网页。第一页为 ‘<a href="http://www.xicidaili.com/nn’，" target="_blank" rel="external">http://www.xicidaili.com/nn’，</a> 第二页 ‘<a href="http://www.xicidaili.com/nn/2’，" target="_blank" rel="external">http://www.xicidaili.com/nn/2’，</a> 第三页 ‘<a href="http://www.xicidaili.com/nn/3’" target="_blank" rel="external">http://www.xicidaili.com/nn/3’</a> ……所以，构造一个网址列表，爬取前十页。前十页就差不多够了，再往后爬更多网页也得不到几个可以用的 IP 。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">urls = [<span class="string">'http://www.xicidaili.com/nn/&#123;&#125;'</span>.format(n) <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)]</div></pre></td></tr></table></figure></p>
<p>最后，完善一下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 爬取西刺代理</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_xicidaili</span><span class="params">(ip_list)</span>:</span></div><div class="line">	urls = [<span class="string">'http://www.xicidaili.com/nn/&#123;&#125;'</span>.format(n) <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>)]</div><div class="line">	<span class="keyword">for</span> url <span class="keyword">in</span> urls:</div><div class="line">	<span class="comment"># 其实每次抓取页面之间应该有一定的时间间隔的，但是由于要验证IP花费很多时间，就省去了这个过程</span></div><div class="line">    	page_data = requests.get(url,headers=headers)</div><div class="line">    	soup = BeautifulSoup(page_data.text,<span class="string">'lxml'</span>)</div><div class="line">    	items = soup.find_all(<span class="string">'tr'</span>)</div><div class="line">    	items.pop(<span class="number">0</span>)</div><div class="line">    	<span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">        	ip = item.select(<span class="string">'td:nth-of-type(2)'</span>)[<span class="number">0</span>].get_text()</div><div class="line">        	port = item.select(<span class="string">'td:nth-of-type(3)'</span>)[<span class="number">0</span>].get_text()</div><div class="line">        	http = <span class="string">'http://'</span> + ip + <span class="string">':'</span> + port</div><div class="line">        	vf(ip_list,http)</div></pre></td></tr></table></figure></p>
<p>暂时就是这样了，别的网站我也试着爬了几个，但是能用的 IP 实在是太少了，不值当的去爬取。就只放出来了这两个网站的爬虫代码。爬取到 IP 暂时就存放在了一个列表中，我正在考虑后续的处理，将爬取到的 IP 放在哪才好。容我想想…… 想想</p>
<h6 id="完整代码在-GitHub"><a href="#完整代码在-GitHub" class="headerlink" title="完整代码在 GitHub"></a>完整代码在 <a href="https://github.com/cl1330104058/Web-Crawler-Test/blob/master/ip_proxy.py" target="_blank" rel="external">GitHub</a></h6></div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://www.songf.win/2017/06/09/Python-爬虫（一）：抓取代理-IP/" data-id="cj41fxmry0006t0wf6lbiq3og" class="article-share-link">分享</a><div class="tags"><a href="/tags/爬虫/">爬虫</a><a href="/tags/Python/">Python</a></div><div class="post-nav"><a href="/2017/06/12/翻译-CentOS-7-安装-MongoDB/" class="pre">[翻译] CentOS 7 安装 MongoDB</a><a href="/2017/06/08/HCNA-笔记（一）：VRP基础/" class="next">HCNA 笔记（一）：VRP基础</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://www.songf.win"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HCNA/">HCNA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/翻译/" style="font-size: 15px;">翻译</a> <a href="/tags/MongoDB/" style="font-size: 15px;">MongoDB</a> <a href="/tags/PhantomJS/" style="font-size: 15px;">PhantomJS</a> <a href="/tags/HCNA/" style="font-size: 15px;">HCNA</a> <a href="/tags/VRP/" style="font-size: 15px;">VRP</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/06/17/CentOS-7-安装PhantomJS/">CentOS 7 安装PhantomJS</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/12/翻译-CentOS-7-安装-MongoDB/">[翻译] CentOS 7 安装 MongoDB</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/09/Python-爬虫（一）：抓取代理-IP/">Python 爬虫（一）：抓取代理 IP</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/08/HCNA-笔记（一）：VRP基础/">HCNA 笔记（一）：VRP基础</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2017 <a href="/." rel="nofollow">Song F.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>